{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Multi-task Gaussian Processes For Multivariate Time Series Imputation\"\n",
    "> \"Using Gpytorch Package\"\n",
    "\n",
    "- toc:true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Zachary Barnes\n",
    "- categories: [Gaussian Processes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pyarrow.parquet as pq\n",
    "import s3fs\n",
    "from config import BUCKET\n",
    "from joblib import Parallel, delayed\n",
    "from utils import train_val_test_split, load_from_s3_to_df\n",
    "\n",
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.RBFKernel()\n",
    "        self.task_covar_module = gpytorch.kernels.IndexKernel(num_tasks=11, rank=1, var_constraint=gpytorch.constraints.Positive())\n",
    "\n",
    "\n",
    "    def forward(self,x,i):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        covar_i = self.task_covar_module(i)\n",
    "        covar = covar_x.mul(covar_i)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar)\n",
    "\n",
    "\n",
    "def MTGP_impute(df, timesteps):\n",
    "    impute_features = ['heart_rate', 'O2_saturation', 'temperature',\\\n",
    "    'systolic_blood_pressure', 'mean_arterial_pressure', \\\n",
    "     'diastolic_blood_pressure', 'respiratory_rate', 'serum_white_blood_count',\\\n",
    "    'serum_glucose', 'pulse_pressure', 'shock_index']\n",
    "    \n",
    "    missing_feats = df.columns[df.isna().all()].tolist()\n",
    "    non_empty_feats = [f for f in set(impute_features) - set(missing_feats)]\n",
    "\n",
    "    feats = []\n",
    "    for f in non_empty_feats:\n",
    "        feats.append(torch.tensor(df[f].values, dtype=torch.float))\n",
    "    \n",
    "    full_train_x = [torch.where(~torch.isnan(f))[0] for f in feats]\n",
    "    if full_train_x == []:\n",
    "        return df\n",
    "    \n",
    "    full_train_x = torch.cat(full_train_x)\n",
    "\n",
    "    full_train_i = []\n",
    "    for i, f in enumerate(feats):\n",
    "        full_train_i.append(torch.full_like(f[~torch.isnan(f)], dtype=torch.long, fill_value=i))\n",
    "    full_train_i = torch.cat(full_train_i)\n",
    "\n",
    "\n",
    "    full_train_y = [f[~torch.isnan(f)] for f in feats]\n",
    "    full_train_y = torch.cat(full_train_y)\n",
    "\n",
    "    # Instantiate likelihood and model\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "    model = MultitaskGPModel((full_train_x, full_train_i), full_train_y, likelihood)\n",
    "\n",
    "    training_iterations = 50\n",
    "\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n",
    "    ], lr=0.1)\n",
    "\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for i in range(training_iterations):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(full_train_x, full_train_i)\n",
    "        loss = -mll(output, full_train_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    test_x = torch.tensor(list(range(timesteps)), dtype=torch.long)\n",
    "    \n",
    "    test_i_tasks = []\n",
    "    for i in range(len(non_empty_feats)):\n",
    "        test_i_tasks.append(torch.full_like(test_x, dtype=torch.long, fill_value=i))\n",
    "        \n",
    "    observed_pred_ys = []\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_samples():\n",
    "        for test_i_task in test_i_tasks:\n",
    "            observed_pred_ys.append(likelihood(model(test_x, test_i_task)))\n",
    "    \n",
    "    for f, preds in zip(non_empty_feats, observed_pred_ys):\n",
    "        df[f] = np.absolute(preds.mean.detach().numpy())\n",
    "        \n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def chunk_train(train: pd.DataFrame):\n",
    "    first_half_train = train.loc[:round(train.shape[0]/2)]\n",
    "    second_half_train = train.loc[round(train.shape[0]/2)+1:]\n",
    "\n",
    "    return first_half_train, second_half_train\n",
    "\n",
    "s3 = s3fs.S3FileSystem()\n",
    "path = \"/data/interim/case_control_train.parquet\"\n",
    "filename = \"case_control_train.parquet\"\n",
    "train = load_from_s3_to_df(path=path, filename=filename)\n",
    "\n",
    "first_half_train, second_half_train = chunk_train(train)\n",
    "\n",
    "impute_first_half_train = Parallel(n_jobs=12)(delayed(MTGP_impute)(df_group, len(df_group)) for patient, df_group in tqdm(first_half_train.groupby('encounter_id')))\n",
    "impute_first_half_train = pd.concat(impute_first_half_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
