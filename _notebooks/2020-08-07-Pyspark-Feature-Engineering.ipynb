{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Time Series Features in PySpark\"\n",
    "> \"Finally, how to get the median and slope for window features in Pyspark\"\n",
    "\n",
    "- toc:true\n",
    "- image: images/icons/pyspark.jpeg\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Zachary Barnes\n",
    "- categories: [Pyspark, Time Series]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This post comes from a place of frustration in not being able to create simple time series features with window functions like the median or slope in Pyspark. This approach is by no means optimal, but it got the job done for purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import sys\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our work more organized, we use pyspark's ML pipeline tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.pipeline import Transformer\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our code all fits into one class, where we specify which feature to use, what size window, and what statistic we want to compute with each window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HourWindowFeat(Transformer):\n",
    "    def __init__(self, hours, feats, stat):\n",
    "        self.hours = hours \n",
    "        self.feats = feats\n",
    "        self.stat = stat\n",
    "        \n",
    "    def this():\n",
    "        this(Identifiable.randomUID(\"HourWindowFeat\"))\n",
    "        \n",
    "    def copy(extra):\n",
    "        defaultCopy(extra)\n",
    "        \n",
    "    def slope(self, series):\n",
    "        if series == [] or len(series) == 1:\n",
    "            return 0\n",
    "        series = np.array(series)\n",
    "        if (series == -1).all():\n",
    "            return 0\n",
    "        x = np.where(series != -1.0)[0]\n",
    "        y = series[np.where(series != -1.0)]\n",
    "        coefficients, residuals, _, _, _ = np.polyfit(x,y,1,full=True)\n",
    "        return coefficients[0]\n",
    "        \n",
    "    def _transform(self, df):\n",
    "        hour_to_sec = lambda i: i * 3600\n",
    "        w = (Window()\n",
    "             .partitionBy(col(\"encounter_id\"))\n",
    "             .orderBy(col(\"time\").cast('long'))\n",
    "             .rangeBetween(-hour_to_sec(self.hours-1), 0))\n",
    "        \n",
    "        if self.stat == 'median':\n",
    "            median_udf = udf(lambda x: float(np.median(x)), FloatType())\n",
    "            for f in self.feats:\n",
    "                output = str(self.hours) + '_' + 'hour' + '_' + self.stat + '_' + f\n",
    "                df = df.withColumn('list', collect_list(f).over(w))\\\n",
    "                        .withColumn(output, round(median_udf('list'), 2))\n",
    "                df = df.drop('list')\n",
    "                \n",
    "        elif self.stat == 'slope':\n",
    "            slope_udf = udf(lambda x: float(self.slope(x)), FloatType())\n",
    "            for f in self.feats:\n",
    "                output = str(self.hours) + '_' + 'hour' + '_' + self.stat + '_' + f\n",
    "                filled_column = 'na_filled_' + f\n",
    "                df = df.drop('list')\n",
    "                df = df.withColumn(filled_column, df[f]).fillna({filled_column:-1})\\\n",
    "                           .withColumn('list', collect_list(filled_column).over(w))\\\n",
    "                           .withColumn(output, round(slope_udf('list'), 2))\n",
    "                df = df.drop('list')\n",
    "                df = df.drop(filled_column)\n",
    "        else:\n",
    "            for f in self.feats:\n",
    "                output = str(self.hours) + '_' + 'hour' + '_' + self.stat.__name__ + '_' + f\n",
    "                df = df.withColumn(output, round(self.stat(f).over(w), 2))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Use Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code I used in my research to identify which features (vital signs, lab values) to use, which window sizes (24, 48, and 72 hours) and what statistics were computed on each(min, max, mean, median, stddev, slope)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_24 =\\\n",
    "['temperature','heart_rate','respiratory_rate','O2_saturation','systolic_blood_pressure',\\\n",
    " 'shock_index','diastolic_blood_pressure', 'pulse_pressure','mean_arterial_pressure','urine_output']\n",
    "feats_48 = \\\n",
    "['temperature', 'heart_rate','respiratory_rate','O2_saturation','systolic_blood_pressure',\\\n",
    " 'shock_index','diastolic_blood_pressure', 'pulse_pressure','mean_arterial_pressure','urine_output', 'serum_glucose', \\\n",
    " 'serum_lactate', 'arterial_blood_gas_lactate', 'arterial_blood_gas_PCO2', 'arterial_blood_gas_PaO2', \\\n",
    " 'arterial_blood_gas_pH', 'venous_blood_gas_lactate', 'venous_blood_gas_PCO2', 'venous_blood_gas_PaO2', 'venous_blood_gas_pH']\n",
    "feats_72 = \\\n",
    "    ['temperature', 'heart_rate','respiratory_rate','O2_saturation','systolic_blood_pressure',\\\n",
    "     'shock_index','diastolic_blood_pressure', 'pulse_pressure', 'mean_arterial_pressure','urine_output','serum_white_blood_count',\\\n",
    "     'serum_lymphocyte_count','serum_immature_granulocytes','serum_eosinophil_count','serum_monocyte_count',\\\n",
    "     'serum_neutrophil_count','serum_hemoglobin', 'serum_hematocrit', 'serum_platelet_count', 'serum_sodium',\\\n",
    "     'serum_chloride', 'serum_CO2', 'serum_BUN', 'serum_creatinine', 'BUN_CR', 'serum_glucose', 'serum_anion_gap',\\\n",
    "     'serum_bilirubin_total', 'serum_AST', 'serum_ALT', 'serum_ALP', 'serum_protein', 'serum_albumin', 'serum_lactate',\\\n",
    "     'arterial_blood_gas_lactate', 'arterial_blood_gas_PCO2', 'arterial_blood_gas_PaO2', 'arterial_blood_gas_pH',\\\n",
    "     'venous_blood_gas_lactate', 'venous_blood_gas_PCO2', 'venous_blood_gas_PaO2', 'venous_blood_gas_pH']\n",
    "feats_120 = \\\n",
    "['serum_white_blood_count','serum_lymphocyte_count','serum_immature_granulocytes','serum_eosinophil_count',\\\n",
    " 'serum_monocyte_count','serum_neutrophil_count','serum_hemoglobin', 'serum_hematocrit', 'serum_platelet_count',\\\n",
    " 'serum_sodium', 'serum_chloride', 'serum_CO2', 'serum_BUN', 'serum_creatinine', 'BUN_CR', 'serum_anion_gap',\\\n",
    " 'serum_bilirubin_total', 'serum_AST', 'serum_ALT', 'serum_ALP', 'serum_protein', 'serum_albumin']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_48 = HourWindowFeat(hours=48, feats=feats_48, stat=min)\n",
    "min_72 = HourWindowFeat(hours=72, feats=feats_72, stat=min)\n",
    "min_120 = HourWindowFeat(hours=120, feats=feats_120, stat=min)\n",
    "max_48 = HourWindowFeat(hours=48, feats=feats_48, stat=max)\n",
    "max_72 = HourWindowFeat(hours=72, feats=feats_72, stat=max)\n",
    "max_120 = HourWindowFeat(hours=120, feats=feats_120, stat=max)\n",
    "mean_48 = HourWindowFeat(hours=48, feats=feats_48, stat=mean)\n",
    "mean_72 = HourWindowFeat(hours=72, feats=feats_72, stat=mean)\n",
    "mean_120 = HourWindowFeat(hours=120, feats=feats_120, stat=mean)\n",
    "median_48 = HourWindowFeat(hours=48, feats=feats_48, stat='median')\n",
    "median_72 = HourWindowFeat(hours=72, feats=feats_72, stat='median')\n",
    "median_120 = HourWindowFeat(hours=120, feats=feats_120, stat='median')\n",
    "slope_72 = HourWindowFeat(hours=72, feats=feats_72, stat='slope')\n",
    "slope_120 = HourWindowFeat(hours=120, feats=feats_120, stat='slope')\n",
    "std_24 = HourWindowFeat(hours=24, feats=feats_24, stat=stddev)\n",
    "std_48 = HourWindowFeat(hours=48, feats=feats_48, stat=stddev)\n",
    "std_72 = HourWindowFeat(hours=72, feats=feats_72, stat=stddev)\n",
    "std_120 = HourWindowFeat(hours=120, feats=feats_120, stat=stddev)\n",
    "\n",
    "FeaturesPipeline =  Pipeline(stages=[min_48, min_72, min_120, max_48, max_72, max_120, mean_48, mean_72, mean_120, median_48, median_72, median_120, slope_72, slope_120, std_24, std_48, std_72, std_120])\n",
    "FeaturesPipeline =  Pipeline(stages=[min_48, min_72, min_120])\n",
    "FeaturesPipeline =  Pipeline(stages=[min_48, min_72, min_120, max_48, max_72, max_120])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we fit our pipeline to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeaturesPipeline =  Pipeline(stages=[min_48, min_72])\n",
    "Featpip = FeaturesPipeline.fit(df)\n",
    "df_feats = Featpip.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be fleshing out this post when I have more time, but please feel free to send me questions/comments on anything related to this!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
